{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-21 19:28:12,858\tINFO worker.py:1528 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "from thesis.utils.utils import setup_ray, save, load, Experiment\n",
    "path = \"D:/Master/Masterarbeit/thesis\"\n",
    "setup_ray(path = path, unidirectional = False, seed=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_args = dict(\n",
    "    fleetsize = 8,\n",
    "    #fleetsize_upper = 12,\n",
    "    max_fleetsize = 20,    \n",
    "    pseudo_routing = False,\n",
    "    pseudo_dispatcher = True,\n",
    "    pseudo_dispatcher_clever = False,\n",
    "    #pseudo_dispatcher_distance = 0.3,\n",
    "    routing_agent_death= True,\n",
    "    death_on_target = False,\n",
    "    transform_dispatching_partobs = True,\n",
    "    direction_reward = -0.1,\n",
    "    sim_config = dict(\n",
    "        dispatch = True,\n",
    "        routing_ma = True,\n",
    "        dispatching_ma = True,\n",
    "        reward_reached_target = 10,\n",
    "        #reward_reached_target_by_time = True, \n",
    "        reward_wrong_target = -1,\n",
    "        reward_removed_for_block = -5, \n",
    "        reward_target_distance = 0,\n",
    "        reward_invalid= -0.1,\n",
    "        reward_duration = -0.5,\n",
    "        reward_pass = 0.2,\n",
    "        block_timeout = 120,\n",
    "        reward_accepted_in_station = 1,\n",
    "        reward_declined_in_station = -1,\n",
    "        routing_interval = 2,\n",
    "        dispatching_interval=360,\n",
    "        io_quote = 0.99,\n",
    "        availability = 0.95,\n",
    "        mttr = 5,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "agv_model = dict(\n",
    "    model = dict(\n",
    "        custom_model = \"gnn_model\",\n",
    "        #custom_action_dist=\"MAActionDistribution\",\n",
    "        custom_model_config = dict(\n",
    "            embed_dim=16,\n",
    "            with_action_mask=False,\n",
    "            with_agvs=True,\n",
    "            with_stations = False,\n",
    "            position_embedd_dim = 0,\n",
    "            ff_embedd_dim = 4,\n",
    "            env_type = \"matrix\",\n",
    "            n_convolutions = 2\n",
    "        )\n",
    "    )\n",
    ")\n",
    "dispatcher_model = dict(\n",
    "    model = dict(\n",
    "        custom_model = \"lin_model\",\n",
    "        #custom_action_dist=\"MAActionDistribution\",\n",
    "        custom_model_config = dict(\n",
    "            embed_dim=64,\n",
    "            with_action_mask=False,\n",
    "            with_agvs=True,\n",
    "            with_stations = True,\n",
    "            position_embedd_dim = 0,\n",
    "            ff_embedd_dim = 4,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-21 19:28:21,285\tINFO simple_q.py:307 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting `simple_optimizer=True` if this doesn't work for you.\n",
      "2023-04-21 19:28:21,295\tINFO algorithm.py:457 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "c:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\alpyne\\client\\utils.py:124: UserWarning: Unzipping to temporary directory (C:\\Users\\Wegma\\AppData\\Local\\Temp\\alpyne_81136_ptfp1km_)\n",
      "  warn(f\"Unzipping to temporary directory ({tmp_dir})\")\n",
      "2023-04-21 19:28:47,525\tINFO trainable.py:164 -- Trainable.setup took 26.245 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "c:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\alpyne\\client\\utils.py:124: UserWarning: Unzipping to temporary directory (C:\\Users\\Wegma\\AppData\\Local\\Temp\\alpyne_12692_c_kqmotv)\n",
      "  warn(f\"Unzipping to temporary directory ({tmp_dir})\")\n",
      "2023-04-22 03:03:01,967\tINFO trainable.py:164 -- Trainable.setup took 15.633 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 2.00 GiB total capacity; 1.28 GiB already allocated; 0 bytes free; 1.31 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n tracebackTraceback (most recent call last):\n  File \"c:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\ray\\rllib\\policy\\torch_policy.py\", line 1068, in _worker\n    self._loss(self, model, self.dist_class, sample_batch)\n  File \"c:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\ray\\rllib\\algorithms\\dqn\\dqn_torch_policy.py\", line 280, in build_q_losses\n    q_tp1, q_logits_tp1, q_probs_tp1, _ = compute_q_values(\n  File \"c:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\ray\\rllib\\algorithms\\dqn\\dqn_torch_policy.py\", line 429, in compute_q_values\n    model_out, state = model(input_dict, state_batches or [], seq_lens)\n  File \"c:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\ray\\rllib\\models\\modelv2.py\", line 259, in __call__\n    res = self.forward(restored, state or [], seq_lens)\n  File \"d:\\Master\\Masterarbeit\\thesis\\exploration\\MiniMatrix\\../..\\thesis\\policies\\ma_gnn_routing.py\", line 216, in forward\n    self.features:torch.Tensor = self.fe(self.obs)\n  File \"c:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"d:\\Master\\Masterarbeit\\thesis\\exploration\\MiniMatrix\\../..\\thesis\\policies\\ma_gnn_routing.py\", line 121, in forward\n    convoluted = self.node_convolutions(\n  File \"c:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"C:\\Users\\Wegma\\AppData\\Local\\Temp\\Wegma_pyg\\tmpq0rlguif.py\", line 18, in forward\n    x = self.module_0(x, edge_index)\n  File \"c:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"c:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\torch_geometric\\nn\\conv\\gatv2_conv.py\", line 236, in forward\n    out = self.propagate(edge_index, x=(x_l, x_r), edge_attr=edge_attr,\n  File \"c:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py\", line 374, in propagate\n    out = self.message(**msg_kwargs)\n  File \"c:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\torch_geometric\\nn\\conv\\gatv2_conv.py\", line 273, in message\n    alpha = (x * self.att).sum(dim=-1)\nRuntimeError: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 2.00 GiB total capacity; 1.28 GiB already allocated; 0 bytes free; 1.31 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n\nIn tower 0 on device cuda:0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\ray\\rllib\\policy\\torch_policy.py:1068\u001b[0m, in \u001b[0;36mTorchPolicy._multi_gpu_parallel_grad_calc.<locals>._worker\u001b[1;34m(shard_idx, model, sample_batch, device)\u001b[0m\n\u001b[0;32m   1064\u001b[0m \u001b[39mwith\u001b[39;00m NullContextManager() \u001b[39mif\u001b[39;00m device\u001b[39m.\u001b[39mtype \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice(  \u001b[39m# noqa: E501\u001b[39;00m\n\u001b[0;32m   1065\u001b[0m     device\n\u001b[0;32m   1066\u001b[0m ):\n\u001b[0;32m   1067\u001b[0m     loss_out \u001b[39m=\u001b[39m force_list(\n\u001b[1;32m-> 1068\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_loss(\u001b[39mself\u001b[39;49m, model, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdist_class, sample_batch)\n\u001b[0;32m   1069\u001b[0m     )\n\u001b[0;32m   1071\u001b[0m     \u001b[39m# Call Model's custom-loss with Policy loss outputs and\u001b[39;00m\n\u001b[0;32m   1072\u001b[0m     \u001b[39m# train_batch.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\ray\\rllib\\algorithms\\dqn\\dqn_torch_policy.py:280\u001b[0m, in \u001b[0;36mbuild_q_losses\u001b[1;34m(policy, model, _, train_batch)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[39m# Target Q-network evaluation.\u001b[39;00m\n\u001b[1;32m--> 280\u001b[0m q_tp1, q_logits_tp1, q_probs_tp1, _ \u001b[39m=\u001b[39m compute_q_values(\n\u001b[0;32m    281\u001b[0m     policy,\n\u001b[0;32m    282\u001b[0m     policy\u001b[39m.\u001b[39;49mtarget_models[model],\n\u001b[0;32m    283\u001b[0m     {\u001b[39m\"\u001b[39;49m\u001b[39mobs\u001b[39;49m\u001b[39m\"\u001b[39;49m: train_batch[SampleBatch\u001b[39m.\u001b[39;49mNEXT_OBS]},\n\u001b[0;32m    284\u001b[0m     explore\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    285\u001b[0m     is_training\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    286\u001b[0m )\n\u001b[0;32m    288\u001b[0m \u001b[39m# Q scores for actions which we know were selected in the given state.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\ray\\rllib\\algorithms\\dqn\\dqn_torch_policy.py:429\u001b[0m, in \u001b[0;36mcompute_q_values\u001b[1;34m(policy, model, input_dict, state_batches, seq_lens, explore, is_training)\u001b[0m\n\u001b[0;32m    427\u001b[0m config \u001b[39m=\u001b[39m policy\u001b[39m.\u001b[39mconfig\n\u001b[1;32m--> 429\u001b[0m model_out, state \u001b[39m=\u001b[39m model(input_dict, state_batches \u001b[39mor\u001b[39;49;00m [], seq_lens)\n\u001b[0;32m    431\u001b[0m \u001b[39mif\u001b[39;00m config[\u001b[39m\"\u001b[39m\u001b[39mnum_atoms\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\ray\\rllib\\models\\modelv2.py:259\u001b[0m, in \u001b[0;36mModelV2.__call__\u001b[1;34m(self, input_dict, state, seq_lens)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontext():\n\u001b[1;32m--> 259\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(restored, state \u001b[39mor\u001b[39;49;00m [], seq_lens)\n\u001b[0;32m    261\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(input_dict, SampleBatch):\n",
      "File \u001b[1;32md:\\Master\\Masterarbeit\\thesis\\exploration\\MiniMatrix\\../..\\thesis\\policies\\ma_gnn_routing.py:216\u001b[0m, in \u001b[0;36mGNNRoutingNet.forward\u001b[1;34m(self, obsdict, state, seq_lengths)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobs \u001b[39m=\u001b[39m obsdict[\u001b[39m\"\u001b[39m\u001b[39mobs\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m--> 216\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures:torch\u001b[39m.\u001b[39mTensor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfe(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobs)\n\u001b[0;32m    217\u001b[0m actions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_net(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures)\n",
      "File \u001b[1;32mc:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n",
      "File \u001b[1;32md:\\Master\\Masterarbeit\\thesis\\exploration\\MiniMatrix\\../..\\thesis\\policies\\ma_gnn_routing.py:121\u001b[0m, in \u001b[0;36mGNNFeatureExtractor.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    119\u001b[0m batch:Batch \u001b[39m=\u001b[39m Batch\u001b[39m.\u001b[39mfrom_data_list(graphs)\n\u001b[1;32m--> 121\u001b[0m convoluted \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnode_convolutions(\n\u001b[0;32m    122\u001b[0m     batch\u001b[39m.\u001b[39;49mx, batch\u001b[39m.\u001b[39;49medge_index, batch\u001b[39m.\u001b[39;49mbatch\n\u001b[0;32m    123\u001b[0m ) \u001b[39m#+ batch.x\u001b[39;00m\n\u001b[0;32m    125\u001b[0m convoluted_by_batch \u001b[39m=\u001b[39m convoluted\u001b[39m.\u001b[39mreshape(node_info\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\Wegma_pyg\\tmpq0rlguif.py:18\u001b[0m, in \u001b[0;36mSequential_672b90.forward\u001b[1;34m(self, x, edge_index, batch)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\"\"\"\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodule_0(x, edge_index)\n\u001b[0;32m     19\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule_1(x, batch)\n",
      "File \u001b[1;32mc:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\torch_geometric\\nn\\conv\\gatv2_conv.py:236\u001b[0m, in \u001b[0;36mGATv2Conv.forward\u001b[1;34m(self, x, edge_index, edge_attr, return_attention_weights)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[39m# propagate_type: (x: PairTensor, edge_attr: OptTensor)\u001b[39;00m\n\u001b[1;32m--> 236\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpropagate(edge_index, x\u001b[39m=\u001b[39;49m(x_l, x_r), edge_attr\u001b[39m=\u001b[39;49medge_attr,\n\u001b[0;32m    237\u001b[0m                      size\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m    239\u001b[0m alpha \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_alpha\n",
      "File \u001b[1;32mc:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:374\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[1;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[0;32m    373\u001b[0m         msg_kwargs \u001b[39m=\u001b[39m res[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(res, \u001b[39mtuple\u001b[39m) \u001b[39melse\u001b[39;00m res\n\u001b[1;32m--> 374\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmessage(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmsg_kwargs)\n\u001b[0;32m    375\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_message_forward_hooks\u001b[39m.\u001b[39mvalues():\n",
      "File \u001b[1;32mc:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\torch_geometric\\nn\\conv\\gatv2_conv.py:273\u001b[0m, in \u001b[0;36mGATv2Conv.message\u001b[1;34m(self, x_j, x_i, edge_attr, index, ptr, size_i)\u001b[0m\n\u001b[0;32m    272\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mleaky_relu(x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnegative_slope)\n\u001b[1;32m--> 273\u001b[0m alpha \u001b[39m=\u001b[39m (x \u001b[39m*\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49matt)\u001b[39m.\u001b[39msum(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m    274\u001b[0m alpha \u001b[39m=\u001b[39m softmax(alpha, index, ptr, size_i)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 2.00 GiB total capacity; 1.28 GiB already allocated; 0 bytes free; 1.31 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m exp \u001b[39m=\u001b[39m Experiment(\u001b[39m\"\u001b[39m\u001b[39mmatrix_routing\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m seed \u001b[39min\u001b[39;00m [\u001b[39m43\u001b[39m, \u001b[39m44\u001b[39m]:\n\u001b[1;32m----> 3\u001b[0m     exp\u001b[39m.\u001b[39;49mexperiment(\n\u001b[0;32m      4\u001b[0m         path \u001b[39m=\u001b[39;49m path,\n\u001b[0;32m      5\u001b[0m         env_args \u001b[39m=\u001b[39;49m env_args, \n\u001b[0;32m      6\u001b[0m         agv_model \u001b[39m=\u001b[39;49m agv_model,\n\u001b[0;32m      7\u001b[0m         dispatcher_model\u001b[39m=\u001b[39;49mdispatcher_model,\n\u001b[0;32m      8\u001b[0m         run_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m08_width\u001b[39;49m\u001b[39m\"\u001b[39;49m, \n\u001b[0;32m      9\u001b[0m         env \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mmatrix\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     10\u001b[0m         algo \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mdqn\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     11\u001b[0m         n_intervals \u001b[39m=\u001b[39;49m\u001b[39m8\u001b[39;49m,\n\u001b[0;32m     12\u001b[0m         \u001b[39m#train_agv = False,\u001b[39;49;00m\n\u001b[0;32m     13\u001b[0m         backup_interval\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m,\n\u001b[0;32m     14\u001b[0m         batch_size\u001b[39m=\u001b[39;49m\u001b[39m300\u001b[39;49m, \u001b[39m#apex + gnn: 50\u001b[39;49;00m\n\u001b[0;32m     15\u001b[0m         seed \u001b[39m=\u001b[39;49m seed,\n\u001b[0;32m     16\u001b[0m         algo_params \u001b[39m=\u001b[39;49m {\u001b[39m\"\u001b[39;49m\u001b[39mgrad_clip\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m1\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mgamma\u001b[39;49m\u001b[39m\"\u001b[39;49m:\u001b[39m0.9\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mexploration_config\u001b[39;49m\u001b[39m\"\u001b[39;49m:{\u001b[39m\"\u001b[39;49m\u001b[39mwarmup_timesteps\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m0\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mepsilon_timesteps\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m200000\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mfinal_epsilon\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m0.02\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39minitial_epsilon\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m1.0\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mtype\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mEpsilonGreedy\u001b[39;49m\u001b[39m\"\u001b[39;49m}},\u001b[39m# \"exploration_config\": {\"type\": \"Curiosity\", \"sub_exploration\": {\"type\": \"StochasticSampling\"}, \"eta\": 0.1}},\u001b[39;49;00m\n\u001b[0;32m     17\u001b[0m         lr \u001b[39m=\u001b[39;49m \u001b[39m1e-3\u001b[39;49m,\n\u001b[0;32m     18\u001b[0m         \u001b[39m#load_agv=\"../../models/matrix_routing/07_reduce_grad_8_20_2023-03-04_17-58-45/checkpoint_000400\",\u001b[39;49;00m\n\u001b[0;32m     19\u001b[0m         \n\u001b[0;32m     20\u001b[0m     )\n",
      "File \u001b[1;32md:\\Master\\Masterarbeit\\thesis\\exploration\\MiniMatrix\\../..\\thesis\\utils\\utils.py:104\u001b[0m, in \u001b[0;36mExperiment.experiment\u001b[1;34m(self, path, env_args, agv_model, dispatcher_model, run_name, algo, env, n_intervals, batch_size, train_agv, train_dispatcher, backup_interval, seed, load_agv, lr, algo_params, n_envs, two_fleets)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_intervals):\n\u001b[0;32m    103\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(backup_interval):\n\u001b[1;32m--> 104\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49mtrain()    \n\u001b[0;32m    105\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39msave(checkpoint_dir)\n",
      "File \u001b[1;32mc:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\ray\\tune\\trainable\\trainable.py:355\u001b[0m, in \u001b[0;36mTrainable.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    354\u001b[0m     skipped \u001b[39m=\u001b[39m skip_exceptions(e)\n\u001b[1;32m--> 355\u001b[0m     \u001b[39mraise\u001b[39;00m skipped \u001b[39mfrom\u001b[39;00m \u001b[39mexception_cause\u001b[39;00m(skipped)\n\u001b[0;32m    357\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(result, \u001b[39mdict\u001b[39m), \u001b[39m\"\u001b[39m\u001b[39mstep() needs to return a dict.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    359\u001b[0m \u001b[39m# We do not modify internal state nor update this result if duplicate.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\ray\\tune\\trainable\\trainable.py:352\u001b[0m, in \u001b[0;36mTrainable.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    350\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m    351\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 352\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep()\n\u001b[0;32m    353\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    354\u001b[0m     skipped \u001b[39m=\u001b[39m skip_exceptions(e)\n",
      "File \u001b[1;32mc:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\ray\\rllib\\algorithms\\algorithm.py:772\u001b[0m, in \u001b[0;36mAlgorithm.step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    764\u001b[0m     (\n\u001b[0;32m    765\u001b[0m         results,\n\u001b[0;32m    766\u001b[0m         train_iter_ctx,\n\u001b[0;32m    767\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_one_training_iteration_and_evaluation_in_parallel()\n\u001b[0;32m    768\u001b[0m \u001b[39m# - No evaluation necessary, just run the next training iteration.\u001b[39;00m\n\u001b[0;32m    769\u001b[0m \u001b[39m# - We have to evaluate in this training iteration, but no parallelism ->\u001b[39;00m\n\u001b[0;32m    770\u001b[0m \u001b[39m#   evaluate after the training iteration is entirely done.\u001b[39;00m\n\u001b[0;32m    771\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 772\u001b[0m     results, train_iter_ctx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_one_training_iteration()\n\u001b[0;32m    774\u001b[0m \u001b[39m# Sequential: Train (already done above), then evaluate.\u001b[39;00m\n\u001b[0;32m    775\u001b[0m \u001b[39mif\u001b[39;00m evaluate_this_iter \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig[\u001b[39m\"\u001b[39m\u001b[39mevaluation_parallel_to_training\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\ray\\rllib\\algorithms\\algorithm.py:2953\u001b[0m, in \u001b[0;36mAlgorithm._run_one_training_iteration\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2951\u001b[0m         \u001b[39m# In case of any failures, try to ignore/recover the failed workers.\u001b[39;00m\n\u001b[0;32m   2952\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m-> 2953\u001b[0m             num_recreated \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtry_recover_from_step_attempt(\n\u001b[0;32m   2954\u001b[0m                 error\u001b[39m=\u001b[39;49me,\n\u001b[0;32m   2955\u001b[0m                 worker_set\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mworkers,\n\u001b[0;32m   2956\u001b[0m                 ignore\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig[\u001b[39m\"\u001b[39;49m\u001b[39mignore_worker_failures\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m   2957\u001b[0m                 recreate\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig[\u001b[39m\"\u001b[39;49m\u001b[39mrecreate_failed_workers\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m   2958\u001b[0m             )\n\u001b[0;32m   2959\u001b[0m     results[\u001b[39m\"\u001b[39m\u001b[39mnum_recreated_workers\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m num_recreated\n\u001b[0;32m   2961\u001b[0m \u001b[39mreturn\u001b[39;00m results, train_iter_ctx\n",
      "File \u001b[1;32mc:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\ray\\rllib\\algorithms\\algorithm.py:2622\u001b[0m, in \u001b[0;36mAlgorithm.try_recover_from_step_attempt\u001b[1;34m(self, error, worker_set, ignore, recreate)\u001b[0m\n\u001b[0;32m   2618\u001b[0m \u001b[39m# Any other exception.\u001b[39;00m\n\u001b[0;32m   2619\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2620\u001b[0m     \u001b[39m# Allow logs messages to propagate.\u001b[39;00m\n\u001b[0;32m   2621\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m0.5\u001b[39m)\n\u001b[1;32m-> 2622\u001b[0m     \u001b[39mraise\u001b[39;00m error\n\u001b[0;32m   2624\u001b[0m removed_workers, new_workers \u001b[39m=\u001b[39m [], []\n\u001b[0;32m   2625\u001b[0m \u001b[39m# Search for failed workers and try to recover (restart) them.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\ray\\rllib\\algorithms\\algorithm.py:2948\u001b[0m, in \u001b[0;36mAlgorithm._run_one_training_iteration\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2946\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timers[TRAINING_ITERATION_TIMER]:\n\u001b[0;32m   2947\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig[\u001b[39m\"\u001b[39m\u001b[39m_disable_execution_plan_api\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m-> 2948\u001b[0m         results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step()\n\u001b[0;32m   2949\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2950\u001b[0m         results \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_exec_impl)\n",
      "File \u001b[1;32mc:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\ray\\rllib\\algorithms\\dqn\\dqn.py:422\u001b[0m, in \u001b[0;36mDQN.training_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    420\u001b[0m     train_results \u001b[39m=\u001b[39m train_one_step(\u001b[39mself\u001b[39m, train_batch)\n\u001b[0;32m    421\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 422\u001b[0m     train_results \u001b[39m=\u001b[39m multi_gpu_train_one_step(\u001b[39mself\u001b[39;49m, train_batch)\n\u001b[0;32m    424\u001b[0m \u001b[39m# Update replay buffer priorities.\u001b[39;00m\n\u001b[0;32m    425\u001b[0m update_priorities_in_replay_buffer(\n\u001b[0;32m    426\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlocal_replay_buffer,\n\u001b[0;32m    427\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig,\n\u001b[0;32m    428\u001b[0m     train_batch,\n\u001b[0;32m    429\u001b[0m     train_results,\n\u001b[0;32m    430\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\ray\\rllib\\execution\\train_ops.py:176\u001b[0m, in \u001b[0;36mmulti_gpu_train_one_step\u001b[1;34m(algorithm, train_batch)\u001b[0m\n\u001b[0;32m    171\u001b[0m         permutation \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mpermutation(num_batches)\n\u001b[0;32m    172\u001b[0m         \u001b[39mfor\u001b[39;00m batch_index \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_batches):\n\u001b[0;32m    173\u001b[0m             \u001b[39m# Learn on the pre-loaded data in the buffer.\u001b[39;00m\n\u001b[0;32m    174\u001b[0m             \u001b[39m# Note: For minibatch SGD, the data is an offset into\u001b[39;00m\n\u001b[0;32m    175\u001b[0m             \u001b[39m# the pre-loaded entire train batch.\u001b[39;00m\n\u001b[1;32m--> 176\u001b[0m             results \u001b[39m=\u001b[39m policy\u001b[39m.\u001b[39;49mlearn_on_loaded_batch(\n\u001b[0;32m    177\u001b[0m                 permutation[batch_index] \u001b[39m*\u001b[39;49m per_device_batch_size, buffer_index\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m\n\u001b[0;32m    178\u001b[0m             )\n\u001b[0;32m    180\u001b[0m             learner_info_builder\u001b[39m.\u001b[39madd_learn_on_batch_results(results, policy_id)\n\u001b[0;32m    182\u001b[0m \u001b[39m# Tower reduce and finalize results.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\ray\\rllib\\policy\\torch_policy.py:593\u001b[0m, in \u001b[0;36mTorchPolicy.learn_on_loaded_batch\u001b[1;34m(self, offset, buffer_index)\u001b[0m\n\u001b[0;32m    590\u001b[0m     batch_fetches[\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtower_\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mcustom_metrics\u001b[39m\u001b[39m\"\u001b[39m: custom_metrics}\n\u001b[0;32m    592\u001b[0m \u001b[39m# Do the (maybe parallelized) gradient calculation step.\u001b[39;00m\n\u001b[1;32m--> 593\u001b[0m tower_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_multi_gpu_parallel_grad_calc(device_batches)\n\u001b[0;32m    595\u001b[0m \u001b[39m# Mean-reduce gradients over GPU-towers (do this on CPU: self.device).\u001b[39;00m\n\u001b[0;32m    596\u001b[0m all_grads \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\ray\\rllib\\policy\\torch_policy.py:1152\u001b[0m, in \u001b[0;36mTorchPolicy._multi_gpu_parallel_grad_calc\u001b[1;34m(self, sample_batches)\u001b[0m\n\u001b[0;32m   1150\u001b[0m         last_result \u001b[39m=\u001b[39m results[\u001b[39mlen\u001b[39m(results) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m]\n\u001b[0;32m   1151\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(last_result[\u001b[39m0\u001b[39m], \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m-> 1152\u001b[0m             \u001b[39mraise\u001b[39;00m last_result[\u001b[39m0\u001b[39m] \u001b[39mfrom\u001b[39;00m \u001b[39mlast_result\u001b[39;00m[\u001b[39m1\u001b[39m]\n\u001b[0;32m   1153\u001b[0m \u001b[39m# Multi device (GPU) case: Parallelize via threads.\u001b[39;00m\n\u001b[0;32m   1154\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1155\u001b[0m     threads \u001b[39m=\u001b[39m [\n\u001b[0;32m   1156\u001b[0m         threading\u001b[39m.\u001b[39mThread(\n\u001b[0;32m   1157\u001b[0m             target\u001b[39m=\u001b[39m_worker, args\u001b[39m=\u001b[39m(shard_idx, model, sample_batch, device)\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1161\u001b[0m         )\n\u001b[0;32m   1162\u001b[0m     ]\n",
      "\u001b[1;31mValueError\u001b[0m: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 2.00 GiB total capacity; 1.28 GiB already allocated; 0 bytes free; 1.31 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n tracebackTraceback (most recent call last):\n  File \"c:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\ray\\rllib\\policy\\torch_policy.py\", line 1068, in _worker\n    self._loss(self, model, self.dist_class, sample_batch)\n  File \"c:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\ray\\rllib\\algorithms\\dqn\\dqn_torch_policy.py\", line 280, in build_q_losses\n    q_tp1, q_logits_tp1, q_probs_tp1, _ = compute_q_values(\n  File \"c:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\ray\\rllib\\algorithms\\dqn\\dqn_torch_policy.py\", line 429, in compute_q_values\n    model_out, state = model(input_dict, state_batches or [], seq_lens)\n  File \"c:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\ray\\rllib\\models\\modelv2.py\", line 259, in __call__\n    res = self.forward(restored, state or [], seq_lens)\n  File \"d:\\Master\\Masterarbeit\\thesis\\exploration\\MiniMatrix\\../..\\thesis\\policies\\ma_gnn_routing.py\", line 216, in forward\n    self.features:torch.Tensor = self.fe(self.obs)\n  File \"c:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"d:\\Master\\Masterarbeit\\thesis\\exploration\\MiniMatrix\\../..\\thesis\\policies\\ma_gnn_routing.py\", line 121, in forward\n    convoluted = self.node_convolutions(\n  File \"c:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"C:\\Users\\Wegma\\AppData\\Local\\Temp\\Wegma_pyg\\tmpq0rlguif.py\", line 18, in forward\n    x = self.module_0(x, edge_index)\n  File \"c:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"c:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\torch_geometric\\nn\\conv\\gatv2_conv.py\", line 236, in forward\n    out = self.propagate(edge_index, x=(x_l, x_r), edge_attr=edge_attr,\n  File \"c:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py\", line 374, in propagate\n    out = self.message(**msg_kwargs)\n  File \"c:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\torch_geometric\\nn\\conv\\gatv2_conv.py\", line 273, in message\n    alpha = (x * self.att).sum(dim=-1)\nRuntimeError: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 2.00 GiB total capacity; 1.28 GiB already allocated; 0 bytes free; 1.31 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n\nIn tower 0 on device cuda:0"
     ]
    }
   ],
   "source": [
    "exp = Experiment(\"matrix_routing\")\n",
    "for seed in [44]:\n",
    "    exp.experiment(\n",
    "        path = path,\n",
    "        env_args = env_args, \n",
    "        agv_model = agv_model,\n",
    "        dispatcher_model=dispatcher_model,\n",
    "        run_name=\"08_width\", \n",
    "        env = \"matrix\",\n",
    "        algo = \"dqn\",\n",
    "        n_intervals =8,\n",
    "        #train_agv = False,\n",
    "        backup_interval=50,\n",
    "        batch_size=300, #apex + gnn: 50\n",
    "        seed = seed,\n",
    "        algo_params = {\"grad_clip\": 1, \"gamma\":0.9, \"exploration_config\":{\"warmup_timesteps\": 0,\"epsilon_timesteps\": 200000,\"final_epsilon\": 0.02,\"initial_epsilon\": 1.0,\"type\": \"EpsilonGreedy\"}},# \"exploration_config\": {\"type\": \"Curiosity\", \"sub_exploration\": {\"type\": \"StochasticSampling\"}, \"eta\": 0.1}},\n",
    "        lr = 1e-3,\n",
    "        #load_agv=\"../../models/matrix_routing/07_reduce_grad_8_20_2023-03-04_17-58-45/checkpoint_000400\",\n",
    "        \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load(exp.trainer, \"agv\", \"../../models/trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save(exp.trainer, \"agv\", \"../../models/trained_routing_newmat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load(exp.trainer, \"agv\", \"../../models/trained_routing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exp.keep_training(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exp.keep_training(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('thesis3_9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a0516e323c1d6337405feeccc202b0dbcb07dc1a4aafa5eedf3cd6ee0d411108"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
