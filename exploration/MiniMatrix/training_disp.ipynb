{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 23:18:04,061\tINFO worker.py:1528 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "from thesis.utils.utils import setup_ray, save, load, Experiment\n",
    "path = \"D:/Master/Masterarbeit/thesis\"\n",
    "setup_ray(path = path, unidirectional = True, seed=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_args = dict(\n",
    "    fleetsize = 4,\n",
    "    max_fleetsize = 20,    \n",
    "    pseudo_routing = True,\n",
    "    pseudo_dispatcher = False,\n",
    "    pseudo_dispatcher_clever = False,\n",
    "    #pseudo_dispatcher_distance = 0.3,\n",
    "    routing_agent_death= False,\n",
    "    death_on_target = False,\n",
    "    transform_dispatching_partobs = True,\n",
    "    direction_reward = 0,\n",
    "    sim_config = dict(\n",
    "        dispatch = True,\n",
    "        routing_ma = True,\n",
    "        dispatching_ma = True,\n",
    "        reward_reached_target = 0,\n",
    "        #reward_reached_target_by_time = True, \n",
    "        reward_wrong_target = 0,\n",
    "        reward_removed_for_block = 0, \n",
    "        reward_target_distance = 0,\n",
    "        reward_invalid= 0,\n",
    "        reward_duration = 0,\n",
    "        block_timeout = 120,\n",
    "        station_separate = False,\n",
    "        reward_accepted_in_station = 2,\n",
    "        reward_declined_in_station = -1,\n",
    "        #reward_part_completed = 5,\n",
    "        #reward_geo_operation=1,\n",
    "        #reward_rework_operation=1,\n",
    "        #reward_respot_operation=1,\n",
    "        reward_reduce = -0.02,\n",
    "        reward_balance = -5,\n",
    "        routing_interval = 2,\n",
    "        dispatching_interval=120,\n",
    "        io_quote = 0.9  ,\n",
    "        availability = 0.9,\n",
    "        mttr = 5,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "agv_model = dict(\n",
    "    model = dict(\n",
    "        custom_model = \"gnn_model\",\n",
    "        #custom_action_dist=\"MAActionDistribution\",\n",
    "        custom_model_config = dict(\n",
    "            embed_dim=16,\n",
    "            with_action_mask=False,\n",
    "            with_agvs=True,\n",
    "            with_stations = False,\n",
    "            position_embedd_dim = 0,\n",
    "            ff_embedd_dim = 4,\n",
    "            env_type = \"matrix\",\n",
    "            n_convolutions = 2\n",
    "        )\n",
    "    )\n",
    ")\n",
    "dispatcher_model = dict(\n",
    "    model = dict(\n",
    "        custom_model = \"lin_model\",\n",
    "        #custom_action_dist=\"MAActionDistribution\",\n",
    "        custom_model_config = dict(\n",
    "            embed_dim=32,\n",
    "            with_action_mask=True,\n",
    "            with_agvs=True,\n",
    "            with_stations = True,\n",
    "            position_embedd_dim = 0,\n",
    "            ff_embedd_dim = 4,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 23:18:14,188\tWARNING ppo.py:351 -- `train_batch_size` (1000) cannot be achieved with your other settings (num_workers=0 num_envs_per_worker=8 rollout_fragment_length=200)! Auto-adjusting `rollout_fragment_length` to 125.\n",
      "2023-03-27 23:18:14,193\tINFO algorithm.py:457 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "c:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\alpyne\\client\\utils.py:124: UserWarning: Unzipping to temporary directory (C:\\Users\\Wegma\\AppData\\Local\\Temp\\alpyne_97099_xxx590g4)\n",
      "  warn(f\"Unzipping to temporary directory ({tmp_dir})\")\n",
      "c:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\alpyne\\client\\utils.py:124: UserWarning: Unzipping to temporary directory (C:\\Users\\Wegma\\AppData\\Local\\Temp\\alpyne_97118_l_4795im)\n",
      "  warn(f\"Unzipping to temporary directory ({tmp_dir})\")\n",
      "c:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\alpyne\\client\\utils.py:124: UserWarning: Unzipping to temporary directory (C:\\Users\\Wegma\\AppData\\Local\\Temp\\alpyne_97125_h99buic8)\n",
      "  warn(f\"Unzipping to temporary directory ({tmp_dir})\")\n",
      "c:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\alpyne\\client\\utils.py:124: UserWarning: Unzipping to temporary directory (C:\\Users\\Wegma\\AppData\\Local\\Temp\\alpyne_97131_pqfx8m8v)\n",
      "  warn(f\"Unzipping to temporary directory ({tmp_dir})\")\n",
      "c:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\alpyne\\client\\utils.py:124: UserWarning: Unzipping to temporary directory (C:\\Users\\Wegma\\AppData\\Local\\Temp\\alpyne_97136_dwr5vzey)\n",
      "  warn(f\"Unzipping to temporary directory ({tmp_dir})\")\n",
      "c:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\alpyne\\client\\utils.py:124: UserWarning: Unzipping to temporary directory (C:\\Users\\Wegma\\AppData\\Local\\Temp\\alpyne_97145_0omfmybn)\n",
      "  warn(f\"Unzipping to temporary directory ({tmp_dir})\")\n",
      "c:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\alpyne\\client\\utils.py:124: UserWarning: Unzipping to temporary directory (C:\\Users\\Wegma\\AppData\\Local\\Temp\\alpyne_97151_3ohp2zvf)\n",
      "  warn(f\"Unzipping to temporary directory ({tmp_dir})\")\n",
      "c:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\alpyne\\client\\utils.py:124: UserWarning: Unzipping to temporary directory (C:\\Users\\Wegma\\AppData\\Local\\Temp\\alpyne_97155__a6u0s70)\n",
      "  warn(f\"Unzipping to temporary directory ({tmp_dir})\")\n",
      "2023-03-27 23:19:09,041\tINFO trainable.py:164 -- Trainable.setup took 54.858 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "c:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\alpyne\\client\\utils.py:124: UserWarning: Unzipping to temporary directory (C:\\Users\\Wegma\\AppData\\Local\\Temp\\alpyne_10939_d7ak9bkn)\n",
      "  warn(f\"Unzipping to temporary directory ({tmp_dir})\")\n",
      "c:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\alpyne\\client\\utils.py:124: UserWarning: Unzipping to temporary directory (C:\\Users\\Wegma\\AppData\\Local\\Temp\\alpyne_10942_04rj1yh5)\n",
      "  warn(f\"Unzipping to temporary directory ({tmp_dir})\")\n",
      "c:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\alpyne\\client\\utils.py:124: UserWarning: Unzipping to temporary directory (C:\\Users\\Wegma\\AppData\\Local\\Temp\\alpyne_10946_f39bvrsv)\n",
      "  warn(f\"Unzipping to temporary directory ({tmp_dir})\")\n",
      "c:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\alpyne\\client\\utils.py:124: UserWarning: Unzipping to temporary directory (C:\\Users\\Wegma\\AppData\\Local\\Temp\\alpyne_10949_xec6pwrx)\n",
      "  warn(f\"Unzipping to temporary directory ({tmp_dir})\")\n",
      "c:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\alpyne\\client\\utils.py:124: UserWarning: Unzipping to temporary directory (C:\\Users\\Wegma\\AppData\\Local\\Temp\\alpyne_10952__g76zccx)\n",
      "  warn(f\"Unzipping to temporary directory ({tmp_dir})\")\n",
      "c:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\alpyne\\client\\utils.py:124: UserWarning: Unzipping to temporary directory (C:\\Users\\Wegma\\AppData\\Local\\Temp\\alpyne_10956_y4zp1j0d)\n",
      "  warn(f\"Unzipping to temporary directory ({tmp_dir})\")\n",
      "c:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\alpyne\\client\\utils.py:124: UserWarning: Unzipping to temporary directory (C:\\Users\\Wegma\\AppData\\Local\\Temp\\alpyne_10959_nqq66s7y)\n",
      "  warn(f\"Unzipping to temporary directory ({tmp_dir})\")\n",
      "c:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\alpyne\\client\\utils.py:124: UserWarning: Unzipping to temporary directory (C:\\Users\\Wegma\\AppData\\Local\\Temp\\alpyne_10963_3wyaywfj)\n",
      "  warn(f\"Unzipping to temporary directory ({tmp_dir})\")\n",
      "2023-03-28 02:37:55,660\tINFO trainable.py:164 -- Trainable.setup took 23.780 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Observation (OrderedDict([('agvs', array([[1.        , 1.        , 0.15384616, ..., 0.        , 0.        ,\n        0.        ],\n       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n        0.        ],\n       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n        0.        ],\n       ...,\n       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n        0.        ],\n       [1.        , 1.        , 0.75502956, ..., 0.        , 0.        ,\n        0.        ],\n       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n        0.        ]], dtype=float32)), ('stat', array([[1.        , 0.9761468 , 1.        , ..., 0.        , 0.        ,\n        0.        ],\n       [1.        , 0.81100917, 1.        , ..., 0.        , 0.        ,\n        0.        ],\n       [1.        , 0.62752295, 1.        , ..., 0.        , 0.        ,\n        0.        ],\n       ...,\n       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n        0.        ],\n       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n        0.        ],\n       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n        0.        ]], dtype=float32)), ('action_mask', array([0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 1., 1., 1., 1., 1.], dtype=float32))]) dtype=None) outside given space (Dict(agvs:Box([[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]], [[1. 1. 1. ... 1. 1. 1.]\n [1. 1. 1. ... 1. 1. 1.]\n [1. 1. 1. ... 1. 1. 1.]\n ...\n [1. 1. 1. ... 1. 1. 1.]\n [1. 1. 1. ... 1. 1. 1.]\n [1. 1. 1. ... 1. 1. 1.]], (20, 53), float32), stat:Box([[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]], [[1. 1. 1. ... 1. 1. 1.]\n [1. 1. 1. ... 1. 1. 1.]\n [1. 1. 1. ... 1. 1. 1.]\n ...\n [1. 1. 1. ... 1. 1. 1.]\n [1. 1. 1. ... 1. 1. 1.]\n [1. 1. 1. ... 1. 1. 1.]], (27, 53), float32), action_mask:Box([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n 1. 1. 1.], (27,), float32)))!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m exp \u001b[39m=\u001b[39m Experiment(\u001b[39m\"\u001b[39m\u001b[39mmatrix_dispatching\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m seed \u001b[39min\u001b[39;00m [\u001b[39m42\u001b[39m,\u001b[39m43\u001b[39m, \u001b[39m44\u001b[39m]:\n\u001b[1;32m----> 3\u001b[0m     exp\u001b[39m.\u001b[39;49mexperiment(\n\u001b[0;32m      4\u001b[0m         path \u001b[39m=\u001b[39;49m path,\n\u001b[0;32m      5\u001b[0m         env_args \u001b[39m=\u001b[39;49m env_args, \n\u001b[0;32m      6\u001b[0m         agv_model \u001b[39m=\u001b[39;49m agv_model,\n\u001b[0;32m      7\u001b[0m         dispatcher_model\u001b[39m=\u001b[39;49mdispatcher_model,\n\u001b[0;32m      8\u001b[0m         run_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m09_rew_balance_-2\u001b[39;49m\u001b[39m\"\u001b[39;49m, \n\u001b[0;32m      9\u001b[0m         env \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mmatrix\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     10\u001b[0m         algo \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mppo\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     11\u001b[0m         n_intervals \u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m,\n\u001b[0;32m     12\u001b[0m         train_agv \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     13\u001b[0m         backup_interval\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m,\n\u001b[0;32m     14\u001b[0m         batch_size\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m, \u001b[39m#apex + gnn: 50\u001b[39;49;00m\n\u001b[0;32m     15\u001b[0m         seed \u001b[39m=\u001b[39;49m seed,\n\u001b[0;32m     16\u001b[0m         algo_params \u001b[39m=\u001b[39;49m {\u001b[39m\"\u001b[39;49m\u001b[39mgamma\u001b[39;49m\u001b[39m\"\u001b[39;49m:\u001b[39m0.9\u001b[39;49m,},\u001b[39m#\"grad_clip\": 1,  \"exploration_config\":{\"warmup_timesteps\": 0,\"epsilon_timesteps\": 200000,\"final_epsilon\": 0.02,\"initial_epsilon\": 1.0,\"type\": \"EpsilonGreedy\"}},# \"exploration_config\": {\"type\": \"Curiosity\", \"sub_exploration\": {\"type\": \"StochasticSampling\"}, \"eta\": 0.1}},\u001b[39;49;00m\n\u001b[0;32m     17\u001b[0m         lr \u001b[39m=\u001b[39;49m \u001b[39m1e-4\u001b[39;49m,\n\u001b[0;32m     18\u001b[0m         \u001b[39m#load_agv=\"../../models/matrix_dispatching/07_rew_conf_process_4_20_2023-03-20_23-05-40/checkpoint_000060\",\u001b[39;49;00m\n\u001b[0;32m     19\u001b[0m         \n\u001b[0;32m     20\u001b[0m     )\n",
      "File \u001b[1;32md:\\Master\\Masterarbeit\\thesis\\exploration\\MiniMatrix\\../..\\thesis\\utils\\utils.py:78\u001b[0m, in \u001b[0;36mExperiment.experiment\u001b[1;34m(self, path, env_args, agv_model, dispatcher_model, run_name, algo, env, n_intervals, batch_size, train_agv, train_dispatcher, backup_interval, seed, load_agv, lr, algo_params)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_intervals):\n\u001b[0;32m     77\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(backup_interval):\n\u001b[1;32m---> 78\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49mtrain()    \n\u001b[0;32m     79\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39msave(checkpoint_dir)\n",
      "File \u001b[1;32mc:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\ray\\tune\\trainable\\trainable.py:355\u001b[0m, in \u001b[0;36mTrainable.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    354\u001b[0m     skipped \u001b[39m=\u001b[39m skip_exceptions(e)\n\u001b[1;32m--> 355\u001b[0m     \u001b[39mraise\u001b[39;00m skipped \u001b[39mfrom\u001b[39;00m \u001b[39mexception_cause\u001b[39;00m(skipped)\n\u001b[0;32m    357\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(result, \u001b[39mdict\u001b[39m), \u001b[39m\"\u001b[39m\u001b[39mstep() needs to return a dict.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    359\u001b[0m \u001b[39m# We do not modify internal state nor update this result if duplicate.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\ray\\tune\\trainable\\trainable.py:352\u001b[0m, in \u001b[0;36mTrainable.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    350\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m    351\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 352\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep()\n\u001b[0;32m    353\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    354\u001b[0m     skipped \u001b[39m=\u001b[39m skip_exceptions(e)\n",
      "File \u001b[1;32mc:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\ray\\rllib\\algorithms\\algorithm.py:772\u001b[0m, in \u001b[0;36mAlgorithm.step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    764\u001b[0m     (\n\u001b[0;32m    765\u001b[0m         results,\n\u001b[0;32m    766\u001b[0m         train_iter_ctx,\n\u001b[0;32m    767\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_one_training_iteration_and_evaluation_in_parallel()\n\u001b[0;32m    768\u001b[0m \u001b[39m# - No evaluation necessary, just run the next training iteration.\u001b[39;00m\n\u001b[0;32m    769\u001b[0m \u001b[39m# - We have to evaluate in this training iteration, but no parallelism ->\u001b[39;00m\n\u001b[0;32m    770\u001b[0m \u001b[39m#   evaluate after the training iteration is entirely done.\u001b[39;00m\n\u001b[0;32m    771\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 772\u001b[0m     results, train_iter_ctx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_one_training_iteration()\n\u001b[0;32m    774\u001b[0m \u001b[39m# Sequential: Train (already done above), then evaluate.\u001b[39;00m\n\u001b[0;32m    775\u001b[0m \u001b[39mif\u001b[39;00m evaluate_this_iter \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig[\u001b[39m\"\u001b[39m\u001b[39mevaluation_parallel_to_training\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\ray\\rllib\\algorithms\\algorithm.py:2953\u001b[0m, in \u001b[0;36mAlgorithm._run_one_training_iteration\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2951\u001b[0m         \u001b[39m# In case of any failures, try to ignore/recover the failed workers.\u001b[39;00m\n\u001b[0;32m   2952\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m-> 2953\u001b[0m             num_recreated \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtry_recover_from_step_attempt(\n\u001b[0;32m   2954\u001b[0m                 error\u001b[39m=\u001b[39;49me,\n\u001b[0;32m   2955\u001b[0m                 worker_set\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mworkers,\n\u001b[0;32m   2956\u001b[0m                 ignore\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig[\u001b[39m\"\u001b[39;49m\u001b[39mignore_worker_failures\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m   2957\u001b[0m                 recreate\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig[\u001b[39m\"\u001b[39;49m\u001b[39mrecreate_failed_workers\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m   2958\u001b[0m             )\n\u001b[0;32m   2959\u001b[0m     results[\u001b[39m\"\u001b[39m\u001b[39mnum_recreated_workers\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m num_recreated\n\u001b[0;32m   2961\u001b[0m \u001b[39mreturn\u001b[39;00m results, train_iter_ctx\n",
      "File \u001b[1;32mc:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\ray\\rllib\\algorithms\\algorithm.py:2622\u001b[0m, in \u001b[0;36mAlgorithm.try_recover_from_step_attempt\u001b[1;34m(self, error, worker_set, ignore, recreate)\u001b[0m\n\u001b[0;32m   2618\u001b[0m \u001b[39m# Any other exception.\u001b[39;00m\n\u001b[0;32m   2619\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2620\u001b[0m     \u001b[39m# Allow logs messages to propagate.\u001b[39;00m\n\u001b[0;32m   2621\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m0.5\u001b[39m)\n\u001b[1;32m-> 2622\u001b[0m     \u001b[39mraise\u001b[39;00m error\n\u001b[0;32m   2624\u001b[0m removed_workers, new_workers \u001b[39m=\u001b[39m [], []\n\u001b[0;32m   2625\u001b[0m \u001b[39m# Search for failed workers and try to recover (restart) them.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\ray\\rllib\\algorithms\\algorithm.py:2948\u001b[0m, in \u001b[0;36mAlgorithm._run_one_training_iteration\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2946\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timers[TRAINING_ITERATION_TIMER]:\n\u001b[0;32m   2947\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig[\u001b[39m\"\u001b[39m\u001b[39m_disable_execution_plan_api\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m-> 2948\u001b[0m         results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step()\n\u001b[0;32m   2949\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2950\u001b[0m         results \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_exec_impl)\n",
      "File \u001b[1;32mc:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\ray\\rllib\\algorithms\\ppo\\ppo.py:404\u001b[0m, in \u001b[0;36mPPO.training_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    400\u001b[0m \u001b[39m@ExperimentalAPI\u001b[39m\n\u001b[0;32m    401\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtraining_step\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResultDict:\n\u001b[0;32m    402\u001b[0m     \u001b[39m# Collect SampleBatches from sample workers until we have a full batch.\u001b[39;00m\n\u001b[0;32m    403\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_by_agent_steps:\n\u001b[1;32m--> 404\u001b[0m         train_batch \u001b[39m=\u001b[39m synchronous_parallel_sample(\n\u001b[0;32m    405\u001b[0m             worker_set\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mworkers, max_agent_steps\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig[\u001b[39m\"\u001b[39;49m\u001b[39mtrain_batch_size\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[0;32m    406\u001b[0m         )\n\u001b[0;32m    407\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    408\u001b[0m         train_batch \u001b[39m=\u001b[39m synchronous_parallel_sample(\n\u001b[0;32m    409\u001b[0m             worker_set\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mworkers, max_env_steps\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig[\u001b[39m\"\u001b[39m\u001b[39mtrain_batch_size\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    410\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\ray\\rllib\\execution\\rollout_ops.py:97\u001b[0m, in \u001b[0;36msynchronous_parallel_sample\u001b[1;34m(worker_set, max_agent_steps, max_env_steps, concat)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[39mwhile\u001b[39;00m (max_agent_or_env_steps \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m agent_or_env_steps \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[0;32m     91\u001b[0m     max_agent_or_env_steps \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     92\u001b[0m     \u001b[39mand\u001b[39;00m agent_or_env_steps \u001b[39m<\u001b[39m max_agent_or_env_steps\n\u001b[0;32m     93\u001b[0m ):\n\u001b[0;32m     94\u001b[0m     \u001b[39m# No remote workers in the set -> Use local worker for collecting\u001b[39;00m\n\u001b[0;32m     95\u001b[0m     \u001b[39m# samples.\u001b[39;00m\n\u001b[0;32m     96\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m worker_set\u001b[39m.\u001b[39mremote_workers():\n\u001b[1;32m---> 97\u001b[0m         sample_batches \u001b[39m=\u001b[39m [worker_set\u001b[39m.\u001b[39;49mlocal_worker()\u001b[39m.\u001b[39;49msample()]\n\u001b[0;32m     98\u001b[0m     \u001b[39m# Loop over remote workers' `sample()` method in parallel.\u001b[39;00m\n\u001b[0;32m     99\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    100\u001b[0m         sample_batches \u001b[39m=\u001b[39m ray\u001b[39m.\u001b[39mget(\n\u001b[0;32m    101\u001b[0m             [worker\u001b[39m.\u001b[39msample\u001b[39m.\u001b[39mremote() \u001b[39mfor\u001b[39;00m worker \u001b[39min\u001b[39;00m worker_set\u001b[39m.\u001b[39mremote_workers()]\n\u001b[0;32m    102\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py:828\u001b[0m, in \u001b[0;36mRolloutWorker.sample\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    821\u001b[0m \u001b[39mif\u001b[39;00m log_once(\u001b[39m\"\u001b[39m\u001b[39msample_start\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    822\u001b[0m     logger\u001b[39m.\u001b[39minfo(\n\u001b[0;32m    823\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mGenerating sample batch of size \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    824\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrollout_fragment_length\n\u001b[0;32m    825\u001b[0m         )\n\u001b[0;32m    826\u001b[0m     )\n\u001b[1;32m--> 828\u001b[0m batches \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_reader\u001b[39m.\u001b[39;49mnext()]\n\u001b[0;32m    829\u001b[0m steps_so_far \u001b[39m=\u001b[39m (\n\u001b[0;32m    830\u001b[0m     batches[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mcount\n\u001b[0;32m    831\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcount_steps_by \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39menv_steps\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m     \u001b[39melse\u001b[39;00m batches[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39magent_steps()\n\u001b[0;32m    833\u001b[0m )\n\u001b[0;32m    835\u001b[0m \u001b[39m# In truncate_episodes mode, never pull more than 1 batch per env.\u001b[39;00m\n\u001b[0;32m    836\u001b[0m \u001b[39m# This avoids over-running the target batch size.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py:92\u001b[0m, in \u001b[0;36mSamplerInput.next\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[39m@override\u001b[39m(InputReader)\n\u001b[0;32m     91\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m SampleBatchType:\n\u001b[1;32m---> 92\u001b[0m     batches \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_data()]\n\u001b[0;32m     93\u001b[0m     batches\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_extra_batches())\n\u001b[0;32m     94\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(batches) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py:285\u001b[0m, in \u001b[0;36mSyncSampler.get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[39m@override\u001b[39m(SamplerInput)\n\u001b[0;32m    283\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_data\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m SampleBatchType:\n\u001b[0;32m    284\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 285\u001b[0m         item \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_env_runner)\n\u001b[0;32m    286\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(item, RolloutMetrics):\n\u001b[0;32m    287\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetrics_queue\u001b[39m.\u001b[39mput(item)\n",
      "File \u001b[1;32mc:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py:671\u001b[0m, in \u001b[0;36m_env_runner\u001b[1;34m(worker, base_env, extra_batch_callback, horizon, normalize_actions, clip_actions, multiple_episodes_in_batch, callbacks, perf_stats, soft_horizon, no_done_at_end, observation_fn, sample_collector, render)\u001b[0m\n\u001b[0;32m    668\u001b[0m t1 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m    669\u001b[0m \u001b[39m# types: Set[EnvID], Dict[PolicyID, List[_PolicyEvalData]],\u001b[39;00m\n\u001b[0;32m    670\u001b[0m \u001b[39m#       List[Union[RolloutMetrics, SampleBatchType]]\u001b[39;00m\n\u001b[1;32m--> 671\u001b[0m active_envs, to_eval, outputs \u001b[39m=\u001b[39m _process_observations(\n\u001b[0;32m    672\u001b[0m     worker\u001b[39m=\u001b[39;49mworker,\n\u001b[0;32m    673\u001b[0m     base_env\u001b[39m=\u001b[39;49mbase_env,\n\u001b[0;32m    674\u001b[0m     active_episodes\u001b[39m=\u001b[39;49mactive_episodes,\n\u001b[0;32m    675\u001b[0m     unfiltered_obs\u001b[39m=\u001b[39;49munfiltered_obs,\n\u001b[0;32m    676\u001b[0m     rewards\u001b[39m=\u001b[39;49mrewards,\n\u001b[0;32m    677\u001b[0m     dones\u001b[39m=\u001b[39;49mdones,\n\u001b[0;32m    678\u001b[0m     infos\u001b[39m=\u001b[39;49minfos,\n\u001b[0;32m    679\u001b[0m     horizon\u001b[39m=\u001b[39;49mhorizon,\n\u001b[0;32m    680\u001b[0m     multiple_episodes_in_batch\u001b[39m=\u001b[39;49mmultiple_episodes_in_batch,\n\u001b[0;32m    681\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    682\u001b[0m     soft_horizon\u001b[39m=\u001b[39;49msoft_horizon,\n\u001b[0;32m    683\u001b[0m     no_done_at_end\u001b[39m=\u001b[39;49mno_done_at_end,\n\u001b[0;32m    684\u001b[0m     observation_fn\u001b[39m=\u001b[39;49mobservation_fn,\n\u001b[0;32m    685\u001b[0m     sample_collector\u001b[39m=\u001b[39;49msample_collector,\n\u001b[0;32m    686\u001b[0m )\n\u001b[0;32m    687\u001b[0m perf_stats\u001b[39m.\u001b[39mincr(\u001b[39m\"\u001b[39m\u001b[39mraw_obs_processing_time\u001b[39m\u001b[39m\"\u001b[39m, time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m t1)\n\u001b[0;32m    688\u001b[0m \u001b[39mfor\u001b[39;00m o \u001b[39min\u001b[39;00m outputs:\n",
      "File \u001b[1;32mc:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py:922\u001b[0m, in \u001b[0;36m_process_observations\u001b[1;34m(worker, base_env, active_episodes, unfiltered_obs, rewards, dones, infos, horizon, multiple_episodes_in_batch, callbacks, soft_horizon, no_done_at_end, observation_fn, sample_collector)\u001b[0m\n\u001b[0;32m    920\u001b[0m prep_obs: EnvObsType \u001b[39m=\u001b[39m raw_obs\n\u001b[0;32m    921\u001b[0m \u001b[39mif\u001b[39;00m preprocessor \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 922\u001b[0m     prep_obs \u001b[39m=\u001b[39m preprocessor\u001b[39m.\u001b[39;49mtransform(raw_obs)\n\u001b[0;32m    923\u001b[0m     \u001b[39mif\u001b[39;00m log_once(\u001b[39m\"\u001b[39m\u001b[39mprep_obs\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    924\u001b[0m         logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mPreprocessed obs: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(summarize(prep_obs)))\n",
      "File \u001b[1;32mc:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\ray\\rllib\\models\\preprocessors.py:283\u001b[0m, in \u001b[0;36mDictFlatteningPreprocessor.transform\u001b[1;34m(self, observation)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[39m@override\u001b[39m(Preprocessor)\n\u001b[0;32m    282\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransform\u001b[39m(\u001b[39mself\u001b[39m, observation: TensorType) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m--> 283\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_shape(observation)\n\u001b[0;32m    284\u001b[0m     array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32)\n\u001b[0;32m    285\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite(observation, array, \u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\ray\\rllib\\models\\preprocessors.py:74\u001b[0m, in \u001b[0;36mPreprocessor.check_shape\u001b[1;34m(self, observation)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     73\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_obs_space\u001b[39m.\u001b[39mcontains(observation):\n\u001b[1;32m---> 74\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     75\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mObservation (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m dtype=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) outside given space (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m)!\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m     76\u001b[0m                 observation,\n\u001b[0;32m     77\u001b[0m                 observation\u001b[39m.\u001b[39mdtype\n\u001b[0;32m     78\u001b[0m                 \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_obs_space, gym\u001b[39m.\u001b[39mspaces\u001b[39m.\u001b[39mBox)\n\u001b[0;32m     79\u001b[0m                 \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     80\u001b[0m                 \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_obs_space,\n\u001b[0;32m     81\u001b[0m             )\n\u001b[0;32m     82\u001b[0m         )\n\u001b[0;32m     83\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     84\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     85\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mObservation for a Box/MultiBinary/MultiDiscrete space \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     86\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mshould be an np.array, not a Python list.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     87\u001b[0m         observation,\n\u001b[0;32m     88\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Observation (OrderedDict([('agvs', array([[1.        , 1.        , 0.15384616, ..., 0.        , 0.        ,\n        0.        ],\n       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n        0.        ],\n       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n        0.        ],\n       ...,\n       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n        0.        ],\n       [1.        , 1.        , 0.75502956, ..., 0.        , 0.        ,\n        0.        ],\n       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n        0.        ]], dtype=float32)), ('stat', array([[1.        , 0.9761468 , 1.        , ..., 0.        , 0.        ,\n        0.        ],\n       [1.        , 0.81100917, 1.        , ..., 0.        , 0.        ,\n        0.        ],\n       [1.        , 0.62752295, 1.        , ..., 0.        , 0.        ,\n        0.        ],\n       ...,\n       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n        0.        ],\n       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n        0.        ],\n       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n        0.        ]], dtype=float32)), ('action_mask', array([0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 1., 1., 1., 1., 1.], dtype=float32))]) dtype=None) outside given space (Dict(agvs:Box([[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]], [[1. 1. 1. ... 1. 1. 1.]\n [1. 1. 1. ... 1. 1. 1.]\n [1. 1. 1. ... 1. 1. 1.]\n ...\n [1. 1. 1. ... 1. 1. 1.]\n [1. 1. 1. ... 1. 1. 1.]\n [1. 1. 1. ... 1. 1. 1.]], (20, 53), float32), stat:Box([[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]], [[1. 1. 1. ... 1. 1. 1.]\n [1. 1. 1. ... 1. 1. 1.]\n [1. 1. 1. ... 1. 1. 1.]\n ...\n [1. 1. 1. ... 1. 1. 1.]\n [1. 1. 1. ... 1. 1. 1.]\n [1. 1. 1. ... 1. 1. 1.]], (27, 53), float32), action_mask:Box([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n 1. 1. 1.], (27,), float32)))!"
     ]
    }
   ],
   "source": [
    "exp = Experiment(\"matrix_dispatching\")\n",
    "for seed in [42,43, 44]:\n",
    "    exp.experiment(\n",
    "        path = path,\n",
    "        env_args = env_args, \n",
    "        agv_model = agv_model,\n",
    "        dispatcher_model=dispatcher_model,\n",
    "        run_name=\"09_rew_balance_-2\", \n",
    "        env = \"matrix\",\n",
    "        algo = \"ppo\",\n",
    "        n_intervals =3,\n",
    "        train_agv = False,\n",
    "        backup_interval=20,\n",
    "        batch_size=1000, #apex + gnn: 50\n",
    "        seed = seed,\n",
    "        algo_params = {\"gamma\":0.9,},#\"grad_clip\": 1,  \"exploration_config\":{\"warmup_timesteps\": 0,\"epsilon_timesteps\": 200000,\"final_epsilon\": 0.02,\"initial_epsilon\": 1.0,\"type\": \"EpsilonGreedy\"}},# \"exploration_config\": {\"type\": \"Curiosity\", \"sub_exploration\": {\"type\": \"StochasticSampling\"}, \"eta\": 0.1}},\n",
    "        lr = 1e-4,\n",
    "        #load_agv=\"../../models/matrix_dispatching/07_rew_conf_process_4_20_2023-03-20_23-05-40/checkpoint_000060\",\n",
    "        \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load(exp.trainer, \"agv\", \"../../models/trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save(exp.trainer, \"dispatcher\", \"../../models/trained_disp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exp.keep_training(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exp.keep_training(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('thesis3_9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a0516e323c1d6337405feeccc202b0dbcb07dc1a4aafa5eedf3cd6ee0d411108"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
