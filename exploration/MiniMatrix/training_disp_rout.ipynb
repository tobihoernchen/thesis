{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 07:09:47,461\tINFO worker.py:1538 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "from thesis.utils.utils import setup_ray, save, load, Experiment\n",
    "path = \"D:/Master/Masterarbeit/thesis\"\n",
    "setup_ray(path = path, unidirectional = False, seed=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_args = dict(\n",
    "    fleetsize = 16,\n",
    "    max_fleetsize = 20,    \n",
    "    pseudo_routing = False,\n",
    "    pseudo_dispatcher = False,\n",
    "    pseudo_dispatcher_clever = False,\n",
    "    #pseudo_dispatcher_distance = 0.3,\n",
    "    routing_agent_death= True,\n",
    "    death_on_target = False,\n",
    "    transform_dispatching_partobs = True,\n",
    "    direction_reward = -0.1,\n",
    "    sim_config = dict(\n",
    "        dispatch = True,\n",
    "        routing_ma = True,\n",
    "        dispatching_ma = True,\n",
    "        reward_reached_target = 10,\n",
    "        #reward_reached_target_by_time = True, \n",
    "        reward_wrong_target = -1,\n",
    "        reward_removed_for_block = -5, \n",
    "        reward_target_distance = 0,\n",
    "        reward_invalid= -0.1,\n",
    "        reward_duration = -0.5,\n",
    "        block_timeout = 120,\n",
    "        station_separate = False,\n",
    "        reward_accepted_in_station = 2,\n",
    "        reward_declined_in_station = -1,\n",
    "        #reward_part_completed = 5,\n",
    "        #reward_geo_operation=1,\n",
    "        #reward_rework_operation=1,\n",
    "        #reward_respot_operation=1,\n",
    "        reward_reduce = -0.02,\n",
    "        reward_balance = -5,\n",
    "        routing_interval = 2,\n",
    "        dispatching_interval=30,\n",
    "        io_quote = 0.9  ,\n",
    "        availability = 0.9,\n",
    "        mttr = 5,\n",
    "        fixed_fleets = True,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "agv_model = dict(\n",
    "    model = dict(\n",
    "        custom_model = \"gnn_model\",\n",
    "        #custom_action_dist=\"MAActionDistribution\",\n",
    "        custom_model_config = dict(\n",
    "            embed_dim=16,\n",
    "            with_action_mask=False,\n",
    "            with_agvs=True,\n",
    "            with_stations = False,\n",
    "            position_embedd_dim = 0,\n",
    "            ff_embedd_dim = 4,\n",
    "            env_type = \"matrix\",\n",
    "            n_convolutions = 2\n",
    "        )\n",
    "    )\n",
    ")\n",
    "dispatcher_model = dict(\n",
    "    model = dict(\n",
    "        custom_model = \"lin_model\",\n",
    "        #custom_action_dist=\"MAActionDistribution\",\n",
    "        custom_model_config = dict(\n",
    "            embed_dim=32,\n",
    "            with_action_mask=True,\n",
    "            with_agvs=True,\n",
    "            with_stations = True,\n",
    "            position_embedd_dim = 0,\n",
    "            ff_embedd_dim = 4,\n",
    "            #with_main_pos_noise = True,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 07:09:58,965\tINFO algorithm.py:501 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "c:\\Users\\Wegma\\.conda\\envs\\thesis3_9\\lib\\site-packages\\alpyne\\client\\utils.py:124: UserWarning: Unzipping to temporary directory (C:\\Users\\Wegma\\AppData\\Local\\Temp\\alpyne_29859_h7abp45p)\n",
      "  warn(f\"Unzipping to temporary directory ({tmp_dir})\")\n",
      "2023-04-03 07:10:27,397\tINFO trainable.py:172 -- Trainable.setup took 28.440 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "2023-04-03 07:10:28,173\tINFO trainable.py:790 -- Restored on 127.0.0.1 from checkpoint: ..\\..\\models\\matrix_together\\01_two_fleets_8_20_2023-04-02_22-17-05\\checkpoint_000400\n",
      "2023-04-03 07:10:28,175\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 400, '_timesteps_total': None, '_time_total': 20762.562623262405, '_episodes_total': 182}\n"
     ]
    }
   ],
   "source": [
    "exp = Experiment(\"matrix_together\")\n",
    "for seed in [42]:\n",
    "    exp.experiment(\n",
    "        path = path,\n",
    "        env_args = env_args, \n",
    "        agv_model = agv_model,\n",
    "        dispatcher_model=dispatcher_model,\n",
    "        run_name=\"01_two_fleets\", \n",
    "        env = \"matrix\",\n",
    "        algo = \"double\",\n",
    "        n_intervals =0,\n",
    "        backup_interval=50,\n",
    "        batch_size=400, \n",
    "        seed = seed,\n",
    "        algo_params = {\"gamma\":0.9, \"exploration_config\":{\"warmup_timesteps\": 0,\"epsilon_timesteps\": 200000,\"final_epsilon\": 0.02,\"initial_epsilon\": 0.02,\"type\": \"EpsilonGreedy\"}},\n",
    "        lr = 1e-4,\n",
    "        two_fleets = True,\n",
    "        load_agv=\"../../models/matrix_together/01_two_fleets_8_20_2023-04-02_22-17-05/checkpoint_000400\"\n",
    "    )\n",
    "    #load(exp.trainer, \"agv\", \"../../models/trained_routing_new\")\n",
    "    #load(exp.trainer, \"dispatcher1\", \"../../models/trained_disp_1\")\n",
    "    #load(exp.trainer, \"dispatcher2\", \"../../models/trained_disp_2\")\n",
    "    exp.keep_training(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exp.trainer.load_checkpoint(\"../../models/matrix_together/01_two_fleets_8_20_2023-04-02_22-17-05/checkpoint_000400\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save(exp.trainer, \"agv\", \"../../models/trained_together_agv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save(exp.trainer, \"dispatcher1\", \"../../models/trained_together_dispatcher1\")\n",
    "#save(exp.trainer, \"dispatcher2\", \"../../models/trained_together_dispatcher2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('thesis3_9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a0516e323c1d6337405feeccc202b0dbcb07dc1a4aafa5eedf3cd6ee0d411108"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
